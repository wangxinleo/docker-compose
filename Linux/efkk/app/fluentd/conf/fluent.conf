<source>
  @type kafka_group

  brokers kafka:9092
  consumer_group fluentd-log
  topics LOG_APP
  format json
  #message_key <key (Optional, for text format only, default is message)>
  #kafka_message_key <key (Optional, If specified, set kafka's message key to this key)>
  #add_headers <If true, add kafka's message headers to record>
  #add_prefix <tag prefix (Optional)>
  #add_suffix <tag suffix (Optional)>
  retry_emit_limit 10
  time_source kafka
  #use_record_time (Deprecated. Use 'time_source record' instead.) <If true, replace event time with contents of 'time' field of fetched record>
  #time_format %Y-%m-%d %H:%M:%S

  # ruby-kafka consumer options
  max_bytes               1048576
  max_wait_time           3
  min_bytes               10000
  offset_commit_interval  3
  offset_commit_threshold 100
  fetcher_max_queue_size  200
  refresh_topic_interval  300
  start_from_beginning    true
</source>


<source>
  @type kafka_group

  brokers kafka:9092
  consumer_group fluentd-log
  topics LOG_INF
  format json
  #message_key <key (Optional, for text format only, default is message)>
  #kafka_message_key <key (Optional, If specified, set kafka's message key to this key)>
  #add_headers <If true, add kafka's message headers to record>
  #add_prefix <tag prefix (Optional)>
  #add_suffix <tag suffix (Optional)>
  retry_emit_limit 10
  time_source kafka
  #use_record_time (Deprecated. Use 'time_source record' instead.) <If true, replace event time with contents of 'time' field of fetched record>
  #time_format %Y-%m-%d %H:%M:%S

  # ruby-kafka consumer options
  max_bytes               1048576
  max_wait_time           3
  min_bytes               10000
  offset_commit_interval  3
  offset_commit_threshold 100
  fetcher_max_queue_size  200
  refresh_topic_interval  300
  start_from_beginning    true
</source>


<source>
  @type kafka_group

  brokers kafka:9092
  consumer_group fluentd-log
  topics LOG_SRV
  format json
  #message_key <key (Optional, for text format only, default is message)>
  #kafka_message_key <key (Optional, If specified, set kafka's message key to this key)>
  #add_headers <If true, add kafka's message headers to record>
  #add_prefix <tag prefix (Optional)>
  #add_suffix <tag suffix (Optional)>
  retry_emit_limit 10
  time_source kafka
  #use_record_time (Deprecated. Use 'time_source record' instead.) <If true, replace event time with contents of 'time' field of fetched record>
  #time_format %Y-%m-%d %H:%M:%S

  # ruby-kafka consumer options
  max_bytes               1048576
  max_wait_time           3
  min_bytes               10000
  offset_commit_interval  3
  offset_commit_threshold 100
  fetcher_max_queue_size  200
  refresh_topic_interval  300
  start_from_beginning    true
</source>


<match LOG_APP>
  @type elasticsearch
  hosts elasticsearch:9200
  user elastic
  password t1izUrGP6uiC7aZBG1m5
  type_name _doc
  logstash_format true
  logstash_prefix panel-app
  logstash_prefix_separator -
  logstash_dateformat %Y.%m.%d

  reload_connections true
  reload_on_failure true

  <buffer>
    @type memory
    flush_interval 60s
    chunk_limit_size 8M
    total_limit_size 512M
    overflow_action block
  </buffer>
</match>

<match LOG_INF>
  @type elasticsearch
  hosts elasticsearch:9200
  user elastic
  password t1izUrGP6uiC7aZBG1m5
  type_name _doc
  logstash_format true
  logstash_prefix panel-inf
  logstash_prefix_separator -
  logstash_dateformat %Y.%m.%d

  reload_connections true
  reload_on_failure true

  <buffer>
    @type memory
    flush_interval 60s
    chunk_limit_size 8M
    total_limit_size 512M
    overflow_action block
  </buffer>
</match>

<match LOG_SRV>
  @type elasticsearch
  hosts elasticsearch:9200
  user elastic
  password t1izUrGP6uiC7aZBG1m5
  type_name _doc
  logstash_format true
  logstash_prefix panel-srv
  logstash_prefix_separator -
  logstash_dateformat %Y.%m.%d

  reload_connections true
  reload_on_failure true

  <buffer>
    @type memory
    flush_interval 60s
    chunk_limit_size 8M
    total_limit_size 512M
    overflow_action block
  </buffer>
</match>